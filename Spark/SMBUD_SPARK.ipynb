{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d120afb9-fe20-4bf8-9998-51bfcefe12ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, ArrayType, TimestampType\n",
    "from pyspark.sql.functions import col, to_timestamp, rand, lit, collect_list, array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "771d0a08-c7fc-40ba-a469-6bce668947df",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"SparkByExamples.com\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46f7d327-0196-4366-b1d3-9114db1cdda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define article custom schema\n",
    "schemaArticle = StructType([\n",
    "\tStructField('_id', StringType(), True),\n",
    "\tStructField('title', StringType(), True),\n",
    "\tStructField('authors',\n",
    "\t\tArrayType(\n",
    "\t\tStructType([\n",
    "\t\t\t StructField('idAuth', StringType(), True),\n",
    "\t\t\t StructField('org', StringType(), True)\n",
    "\t\t]), True)\n",
    "\t),\n",
    "\tStructField('n_citation', IntegerType(), True), \n",
    "\tStructField('abstract', StringType(), True), \n",
    "\tStructField('doi', StringType(), True),\n",
    "\tStructField('keywords', ArrayType(StringType()), True),\n",
    "\tStructField('isbn', StringType(), True),\n",
    "\tStructField('page_start', StringType(), True),\n",
    "\tStructField('page_end', StringType(), True),\n",
    "\tStructField('year', IntegerType(), True),\n",
    "\tStructField('fos', ArrayType(StringType()), True),\n",
    "\tStructField('references', ArrayType(StringType()), True),\n",
    "\tStructField('venue',\n",
    "\t\tStructType([\n",
    "\t\t\t StructField('raw', StringType(), True),\n",
    "\t\t\t StructField('type', IntegerType(), True),\n",
    "\t\t\t StructField('issue', StringType(), True),\n",
    "\t\t\t StructField('volume', StringType(), True),\n",
    "\t\t\t StructField('publisher', StringType(), True)\n",
    "\t\t])\n",
    "\t),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68a9536e-d248-4dd9-9afd-64515f9a79ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we decided to use import from schema to explicitly show data structure\n",
    "df_articles = spark.read.schema(schemaArticle).json(\"./dblp_sample_filtered_spark.json\", multiLine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deaef0ca-2e9f-4ba6-b3cc-9456c199502e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#issue, volume and publisher attributes inside venue are moved back in the root structure and removed from the inner struct\n",
    "df_articles = df_articles.withColumn(\"issue\", col(\"venue.issue\")) \\\n",
    "\t\t\t\t\t\t.withColumn(\"volume\", col(\"venue.volume\")) \\\n",
    "\t\t\t\t\t\t.withColumn(\"publisher\", col(\"venue.publisher\")) \\\n",
    "\t\t\t\t\t\t.withColumn(\"venue\", col(\"venue\").dropFields(\"issue\", \"volume\", \"publisher\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cd3e637-2843-4a34-b71d-9d5cea4e8efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VENUES COLLECTION\n",
    "#A new dataframe is created with attributes of venue and the _id of the article\n",
    "#then it is all grouped by venue attributes and a list of the articles id for each venue is created\n",
    "#finally we drop rows with null raw to delete inconsistent tuple\n",
    "df_venues = df_articles.select(\"venue.raw\", \"venue.type\", \"_id\") \\\n",
    "\t\t\t\t\t\t.groupBy(\"raw\", \"type\") \\\n",
    "\t\t\t\t\t\t.agg(collect_list(\"_id\").alias(\"artIds\")) \\\n",
    "\t\t\t\t\t\t.dropna(subset=[\"raw\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "586d555c-4412-471d-90dc-25c6fd9ada30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the schema for the DataFrame of Authors\n",
    "schemaAuthors = StructType([\n",
    "    StructField(\"_id\", StringType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"nationality\", StringType(), True),\n",
    "    StructField(\"articles\", ArrayType(StringType(), True), True),\n",
    "    StructField(\"bio\", StringType(), True),\n",
    "    StructField(\"email\", StringType(), True),\n",
    "    StructField(\"orcid\", StringType(), True),\n",
    "    StructField(\"dob\", TimestampType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12ef4ef3-ee77-4742-b378-8a90b8ae4e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we can keep only the raw attribute of the venue\n",
    "df_articles = df_articles.withColumn(\"venue_raw\", col(\"venue.raw\")).drop(\"venue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8868f13b-8b1d-4b0e-8c0d-a7cb2721ed56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/column.py:419: FutureWarning: A column as 'key' in getItem is deprecated as of Spark 3.0, and will not be supported in the future release. Use `column[key]` or `column.key` syntax instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#we now add a generated field inside venues collection\n",
    "#for each venue a random city is selected that should represent the place where the venue was held\n",
    "citiesList = [\"New York\", \"London\", \"Paris\", \"Berlin\", \"Madrid\", \"Rome\", \"Dublin\", \"Copenhagen\", \"Vienna\", \"Amsterdam\", \"Brussels\", \"Lisbon\", \"Prague\", \"Athens\", \"Budapest\", \"Warsaw\", \"Zurich\", \"Luxembourg\", \"Oslo\", \"Stockholm\", \"Helsinki\", \"Moscow\", \"Istanbul\", \"Kiev\", \"Minsk\", \"Belgrade\", \"Bucharest\", \"Sofia\", \"Tallinn\", \"Riga\", \"Vilnius\", \"Tbilisi\", \"Yerevan\", \"Baku\", \"Dubai\", \"Abu Dhabi\", \"Doha\", \"Manama\", \"Muscat\", \"Riyadh\", \"Jeddah\", \"Mecca\", \"Medina\", \"Kuala Lumpur\", \"Singapore\", \"Hong Kong\", \"Shanghai\", \"Beijing\", \"Tokyo\", \"Seoul\", \"Bangkok\", \"Manila\"]\n",
    "cities = array([lit(city) for city in citiesList])\n",
    "df_venues = df_venues.withColumn(\"city\", cities.getItem((rand() * len(citiesList)).cast(\"int\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a40b4b24-c483-4912-8278-7e98928f4a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUTHORS COLLECTION\n",
    "#We simply import from json with autogenerated schema and the conversion from string to timestamp is applied\n",
    "df_authors = spark.read.schema(schemaAuthors).json(\"./dblp_sample_reverted_filtered_spark.json\", multiLine=True)\n",
    "df_authors = df_authors.withColumn(\"dateofbirth\", to_timestamp(df_authors[\"dob\"], \"yyyy-MM-dd'T'HH:mm:ss'Z'\")) \\\n",
    "\t\t\t\t\t\t.drop(\"dob\") \\\n",
    "\t\t\t\t\t\t.withColumnRenamed(\"dateofbirth\", \"dob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "396efc6f-7824-4e47-89cd-24b973d1cc0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- authors: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- idAuth: string (nullable = true)\n",
      " |    |    |-- org: string (nullable = true)\n",
      " |-- n_citation: integer (nullable = true)\n",
      " |-- abstract: string (nullable = true)\n",
      " |-- doi: string (nullable = true)\n",
      " |-- keywords: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- isbn: string (nullable = true)\n",
      " |-- page_start: string (nullable = true)\n",
      " |-- page_end: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- fos: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- references: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- issue: string (nullable = true)\n",
      " |-- volume: string (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- venue_raw: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- _id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- nationality: string (nullable = true)\n",
      " |-- articles: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- bio: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- orcid: string (nullable = true)\n",
      " |-- dob: timestamp (nullable = true)\n",
      "\n",
      "root\n",
      " |-- raw: string (nullable = true)\n",
      " |-- type: integer (nullable = true)\n",
      " |-- artIds: array (nullable = false)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- city: string (nullable = true)\n",
      "\n",
      "+--------------------+----+--------------------+---------+\n",
      "|                 raw|type|              artIds|     city|\n",
      "+--------------------+----+--------------------+---------+\n",
      "|2006 IEEE Interna...|   0|[53e9a281b7602d97...|   Lisbon|\n",
      "|2007 IEEE Interna...|   0|[53e9a317b7602d97...|    Dubai|\n",
      "|2009 IEEE INTERNA...|   0|[53e99fd6b7602d97...|Stockholm|\n",
      "|2010 Internationa...|   0|[53e99fddb7602d97...|    Sofia|\n",
      "|25 Years of Model...|   0|[53e99fe9b7602d97...|  Vilnius|\n",
      "|2ND INTERNATIONAL...|null|[53e99f94b7602d97...|   Lisbon|\n",
      "|                 4OR|   0|[53e99fe4b7602d97...|    Paris|\n",
      "|7TH INTERNATIONAL...|null|[53e9a31fb7602d97...|Hong Kong|\n",
      "|A Quarterly Journ...|   1|[53e99fe4b7602d97...|   Manama|\n",
      "|              A2CWiC|   0|[53e99fddb7602d97...|     Oslo|\n",
      "+--------------------+----+--------------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_articles.printSchema()\n",
    "df_authors.printSchema()\n",
    "df_venues.printSchema()\n",
    "df_venues.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b438276-9744-4321-96d9-3daf1b9ee18d",
   "metadata": {},
   "source": [
    "# Data creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cabc87d0-de4e-498a-bf66-4b827c2264a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from datetime import datetime\n",
    "from pyspark.sql.functions import from_unixtime, cast\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Create a datetime object for the author's date of birth\n",
    "dob = datetime.strptime(\"March 7, 1975\", \"%B %d, %Y\")\n",
    "\n",
    "# Convert the datetime object to a timestamp\n",
    "\n",
    "\n",
    "# Create a new Row object with the values for the new author\n",
    "new_author = Row(\n",
    "    _id=\"638d9c6dae9ea0d19fad7a78\",\n",
    "    name=\"Emanuele Delle Valle \",\n",
    "    nationality=\"it\",\n",
    "    # Set values for any other required columns\n",
    "    articles=[],\n",
    "    bio=\"Emanuele Della Valle holds a PhD in Computer Science from the \\\n",
    "        Vrije Universiteit Amsterdam and a Master degree in Computer Science\\\n",
    "        and Engineering from Politecnico di Milano. He is associate professor\\\n",
    "        at the Department of Electronics, Information and Bioengineering of\\\n",
    "        the Politecnico di Milano.\",\n",
    "    email=\"emanuele.dellavalle@gmail.com \",\n",
    "    orcid=\"0000-0002-5176 -5885\",\n",
    "    dob=dob\n",
    ")\n",
    "\n",
    "# Add the new row to the DataFrame\n",
    "df_authors = df_authors.union(spark.createDataFrame([new_author], schema = schemaAuthors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb8c6a04-ef96-4454-b41c-f3b84d34e89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------+--------+--------------------+--------------------+--------------------+-------------------+\n",
      "|                 _id|                name|nationality|articles|                 bio|               email|               orcid|                dob|\n",
      "+--------------------+--------------------+-----------+--------+--------------------+--------------------+--------------------+-------------------+\n",
      "|638d9c6dae9ea0d19...|Emanuele Delle Va...|         it|      []|Emanuele Della Va...|emanuele.dellaval...|0000-0002-5176 -5885|1975-03-07 00:00:00|\n",
      "+--------------------+--------------------+-----------+--------+--------------------+--------------------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_authors.filter(col(\"_id\") == \"638d9c6dae9ea0d19fad7a78\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "378c58cb-c44f-4357-938b-783580ab8cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_authors =  [Row(\"638db170ae9ea0d19fad7a79\", \"Politecnico di Milano\"), Row(\"638db170ae9ea0d19fad7a7a\", \"Politecnico di Milano\")]\n",
    "\n",
    "new_article = Row(\n",
    "    _id=\"638db237d794b76f45c77916\",\n",
    "    title=\"An extensive study of C-SMOTE, a Continuous Synthetic Minority Oversampling Technique for Evolving Data Streams\",\n",
    "    authors=new_authors,\n",
    "    n_citation=3,\n",
    "    abstract = \"Streaming Machine Learning (SML) studies algorithms that update their models,\\\n",
    "        given an unbounded and often non-stationary flow of data performing a single pass. Online \\\n",
    "        class imbalance learning is a branch of SML that combines the challenges of both class imbalance\\\n",
    "        and concept drift. In this paper, we investigate the binary classification problem by rebalancing\\\n",
    "        an imbalanced stream of data in the presence of concept drift, accessing one sample at a time.\",\n",
    "    doi=\"10.1016/j.eswa.2022.116630\",\n",
    "    keywords=[\"Evolving Data Stream\",\"Streaming\",\"Concept drift\",\"Balancing\"],\n",
    "    isbn=\"123-4-567-89012-3\",\n",
    "    page_start=\"39\",\n",
    "    page_end=\"46\",\n",
    "    year=2022,\n",
    "    fos=[\"Computer Science\",\"Stream Reasoning\",\"Big Data\"],\n",
    "    references=[\"53e99fe4b7602d97028bf743\",\"53e99fddb7602d97028bc085\"],\n",
    "    issue=\"1\",\n",
    "    volume=\"196\",\n",
    "    publisher=\"Elsevier\",\n",
    "    venue_raw=\"ESA\"\n",
    ")\n",
    "\n",
    "# Add the new row to the DataFrame\n",
    "df_articles = df_articles.union(spark.createDataFrame([new_article]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59135eb0-f892-45e5-9d59-80a1910b8391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+-----------------+----------+--------+----+--------------------+--------------------+-----+------+---------+---------+\n",
      "|                 _id|               title|             authors|n_citation|            abstract|                 doi|            keywords|             isbn|page_start|page_end|year|                 fos|          references|issue|volume|publisher|venue_raw|\n",
      "+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+-----------------+----------+--------+----+--------------------+--------------------+-----+------+---------+---------+\n",
      "|638db237d794b76f4...|An extensive stud...|[{638db170ae9ea0d...|         3|Streaming Machine...|10.1016/j.eswa.20...|[Evolving Data St...|123-4-567-89012-3|        39|      46|2022|[Computer Science...|[53e99fe4b7602d97...|    1|   196| Elsevier|      ESA|\n",
      "+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+-----------------+----------+--------+----+--------------------+--------------------+-----+------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_articles.filter(col(\"_id\") == \"638db237d794b76f45c77916\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b314f663-c6b7-44bb-a5db-e6203f2e42b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_venue = Row(\n",
    "    raw=\"ESA\",\n",
    "    type=1,\n",
    "    artIds=[\"638db237d794b76f45c77916\"],\n",
    "    city=\"Montreal\"\n",
    ")\n",
    "\n",
    "# Add the new row to the DataFrame\n",
    "df_venues = df_venues.union(spark.createDataFrame([new_venue]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "499ef802-20c7-417a-b192-1722f1db1309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+--------------------+---------+\n",
      "|raw|type|              artIds|     city|\n",
      "+---+----+--------------------+---------+\n",
      "|ESA|   0|[53e99fddb7602d97...|Hong Kong|\n",
      "|ESA|   1|[638db237d794b76f...| Montreal|\n",
      "+---+----+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_venues.filter(col(\"raw\") == \"ESA\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b70a1e1-de68-4cce-93c9-dfaed0a22de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the new article to the new author\n",
    "import pyspark.sql.functions as f\n",
    "df_authors = df_authors.withColumn(\n",
    "    \"articles\",\n",
    "    f.when(f.col(\"_id\") == \"638d9c6dae9ea0d19fad7a78\",\n",
    "        f.array_union(df_authors.articles, f.array(f.lit(\"638db237d794b76f45c77916\"))))\n",
    "    .otherwise(f.col(\"articles\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db4b9bcb-b893-4a4e-b38f-5e4155ea5a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+-------------------+\n",
      "|                 _id|                name|nationality|            articles|                 bio|               email|               orcid|                dob|\n",
      "+--------------------+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+-------------------+\n",
      "|638d9c6dae9ea0d19...|Emanuele Delle Va...|         it|[638db237d794b76f...|Emanuele Della Va...|emanuele.dellaval...|0000-0002-5176 -5885|1975-03-07 00:00:00|\n",
      "+--------------------+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_authors.filter(col(\"_id\") == \"638d9c6dae9ea0d19fad7a78\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f760314c-506e-47ed-b69a-71bcb7f0fe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#increment number of citations\n",
    "df_articles = df_articles.withColumn(\n",
    "    \"n_citation\",\n",
    "    f.when(f.col(\"_id\") == \"638db237d794b76f45c77916\",\n",
    "       df_articles.n_citation+1)\n",
    "    .otherwise(f.col(\"n_citation\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dbb4991b-0a8c-46fa-af47-0e9d5075b698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+-----------------+----------+--------+----+--------------------+--------------------+-----+------+---------+---------+\n",
      "|                 _id|               title|             authors|n_citation|            abstract|                 doi|            keywords|             isbn|page_start|page_end|year|                 fos|          references|issue|volume|publisher|venue_raw|\n",
      "+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+-----------------+----------+--------+----+--------------------+--------------------+-----+------+---------+---------+\n",
      "|638db237d794b76f4...|An extensive stud...|[{638db170ae9ea0d...|         5|Streaming Machine...|10.1016/j.eswa.20...|[Evolving Data St...|123-4-567-89012-3|        39|      46|2022|[Computer Science...|[53e99fe4b7602d97...|    1|   196| Elsevier|      ESA|\n",
      "+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+-----------------+----------+--------+----+--------------------+--------------------+-----+------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_articles.filter(col(\"_id\") == \"638db237d794b76f45c77916\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6949121c-c92c-41c7-aff2-275663664646",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
